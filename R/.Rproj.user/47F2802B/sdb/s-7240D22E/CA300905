{
    "contents" : "##########################################################################\n# PROGRAM: RasterUpSample.R\n# USE: UP SAMPLES A RASTER USING ROBUST REGRESSION \n# REQUIRES: RGDAL FORMAT COMPATABLE RASTERS\n#           PACKAGES: MASS, sp, raster, rgdal \n#\n# ARGUMENTS: \n#  x                X (HIGHER RESOULTION) INDEPENDENT VARIABLE RASTER \n#  y                Y (LOWER RESOULTION) DEPENDENT VARIABLE RASTER    \n#  p                PERCENT SUBSAMPLE\n#  sample.type      TYPE OF SAMPLE (random OR systematic); DEFAULT IS random\n#  file             IF SPECIFIED, A RASTER SURFACE WILL BE WRITTEN TO DISK.\n#                     THE FILE EXTENTION WILL DICTATE THE RASTER FORMAT.\n#  ...              ADDITIONAL ARGUMENTS PASSED TO predict\n#\n# EXAMPLES: \n#    setwd(\"C:/ANALYSIS/TEST/RRR\")\n#    x <- paste(getwd(), paste(\"elev\", \"img\", sep=\".\"), sep=\"/\")\n#    y <- paste(getwd(), paste(\"precip90\", \"img\", sep=\".\"), sep=\"/\")\n#    RasterUpSample(x=x, y=y, p=0.01, sample.type=\"random\", filename=\"RPREDICT.img\")\n#      praster <- raster( paste(getwd(), \"RPREDICT.img\", sep=\"/\"))\n#      Y <- raster(paste(getwd(), paste(\"precip90\", \"img\", sep=\".\"), sep=\"/\"))\n#     op <- par(mfrow = c(1, 2))\n#        plot(Y)\n#        plot(praster) \n#     par(op)\n#\n# CONTACT: \n#     Jeffrey S. Evans\n#     Senior Landscape Ecologist  \n#     The Nature Conservancy\n#     Central Science/DbyD\n#     Laramie, WY 82070 \n#     jeffrey_evans@tnc.org\n#     (970) 672-6766\n##########################################################################\nRasterUpSample <- function(x, y, p, sample.type=\"random\", filename=FALSE, ...) {\n   if (!require(MASS)) stop(\"MASS PACKAGE MISSING\")\n     if (!require(sp)) stop(\"sp PACKAGE MISSING\")\n     if (!require(raster)) stop(\"raster PACKAGE MISSING\")\n   if (!require(rgdal)) stop(\"rgdal PACKAGE MISSING\")\n\t  X <- stack(x)\n\t  Y <- raster(y) \n     if(sample.type == \"random\") { \n\t   print(\"SAMPLE TYPE RANDOM\")\n\t    SubSamps <- sampleRandom(X, ((nrow(X)*ncol(X))*p), sp=TRUE)\n\t\t} \n\t if(sample.type == \"systematic\") {\n       print(\"SAMPLE TYPE SYSTEMATIC\")\n      SubSamps <- sampleRegular(X, ((nrow(X)*ncol(X))*p), asRaster=TRUE)\t \n      SubSamps <- as(SubSamps, 'SpatialPointsDataFrame') \n\t\t}  \t \n\t  Yvalues <- extract(Y, SubSamps)\n    SubSamps@data <- data.frame(SubSamps@data, Y=Yvalues) \n   ( rrr <- rlm(as.formula(paste(names(SubSamps@data)[2], \".\", sep=\" ~ \")), \n                data=SubSamps@data, scale.est=\"Huber\", psi=psi.hampel, \n                init=\"lts\") )\n  if (filename != FALSE) {\n  \tpredict(X, rrr, filename=filename, na.rm=TRUE, progress='window', \n\t        overwrite=TRUE, ...)\n     print(paste(\"RASTER WRITTEN TO\", filename, sep=\": \"))\t\t\t\n\t}\n     print(paste(\"MEAN RESIDUAL ERROR\", round(mean(rrr$residuals), digits=5), sep=\": \"))\n     print(paste(\"AIC\", round(AIC(rrr), digits=5), sep=\": \"))   \n  return(rrr)\t\t\n}\n\n###################################################################\n# PROGRAM: MultiColinear.R                \n# PURPOSE: IDENTIFY MULTI-COLINEAR VARIABLES USING QR MATRIX DECOMPOSITION                   \n#\n# ARGUMENTS: \n#       X   A DATAFRAME \n#       p   MULTI-COLINEARITY THRESHOLD (DEFAULT 1e-07)\n#\n# VALUE:\n#       TEST STATISTIC MESSAGE\n#       CHARACTER VECTOR OF POTENTIAL MULTI-COLINEAR VARIABLES\n#\n# NOTES:\n#       COLINEARITY THRESHOLDS MUST BE ADJUSTED BASED ON NUMBER OF \n#        X-VARIABLES. FOR SMALL NUMBER OF VARIABLES (<20) USE 1e-07 \n#        FOR LARGE NUMBER (>20) USE 0.05 \n#\n# EXAMPLES: \n#   # DUMMY DATA\n#   test = data.frame(v1=seq(0.1, 5, length=100), v2=seq(0.1, 5, length=100), \n#                     v3=dnorm(runif(100)), v4=dnorm(runif(100)) ) \n#\n#   # TEST FOR MULTICOLINEAR VARABLE(s)\n#   MultiColinear(test[,c(1,3)])\n#   cl <- MultiColinear(test)\n#\n#   # PCA BIPLOT OF VARIABLES \n#    pca.test <- prcomp(test[,1:ncol(test)], scale=TRUE)\n#    biplot(pca.test, arrow.len=0.1, xlabs=rep(\".\", length(pca.test$x[,1])))        \n#\n#   # REMOVE IDENTIFIED VARIABLE(S)\n#   test <- test[, -which(names(test)==cl)]\n#\n# REFERENCES:\n#  Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) The New S Language. \n#     Wadsworth & Brooks/Cole. \n#\n#  Dongarra, J. J., Bunch, J. R., Moler, C. B. and Stewart, G. W. (1978) \n#     LINPACK Users Guide. Philadelphia: SIAM Publications. \n#\n##########################################################################\nMultiColinear <- function(x, p=1e-07) {\n if (!inherits(x, \"data.frame\")) stop(\"X MUST BE A data.frame\")\n   if ( (dim(x)[2] < 2) == TRUE) stop(\"NOT ENOUGH VARIABLES TO TEST\")\n     xtest <- x\n     x.names <- names(xtest)\n  qrx <- qr(xtest, tol=p)\n    if (length(names(xtest)[qrx$pivot[1:qrx$rank]]) != length(xtest) )  \n      {  \n        keep <- names(xtest)[qrx$pivot[1:qrx$rank]]\n         warning(\"MULTI-COLINEAR VARIABLES: \", paste(setdiff(x.names, keep), collapse = \",\"))\n      return(paste(setdiff(x.names, keep)))\n    } else { print(\" NO MULTICOLINEAR VARIABLES IDENTIFIED\")\n  } \n}\n\n##########################################################################\n# PROGRAM: rf.modelSel (FOR CLASSIFICATION OR REGRESSION)\n# USE: RANDOM FOREST MODEL SELECTION USING SCALED IMPORTANCE VALUES\n# REQUIRES: >= R 2.14.0, randomForest 4.6-7 \n#           \n# ARGUMENTS: \n#       ydata      Y Data for model \n#       xdata      X Data for model\n#       imp.scale  Type of scaling for importance values (mir or se), default is mir\n#       r          Vector of importance percentiles to test i.e., c(0.1, 0.2, 0.5, 0.7, 0.9)\n#       final      Run final model with selected variables (TRUE/FALSE)\n#       plot.imp   Plot variable importance (TRUE/FALSE)\n#       parsimony  THRESHOLD FOR ASSESSING COMPETING MODEL 0-1 SCALE (IF NULL NOT RUN)\n#       ...        Arguments to pass to randomForest (e.g., ntree=1000, replace=TRUE, proximity=TRUE)\n#\n# VALUE:\n#     A LIST WITH THE FOLLOWING OBJECTS\n#         rf.final - FINAL RF MODEL (LIST OBJECT) USING SELECTED VARIABLES (IF final=TRUE)\n#           SELVARS - LIST OF FINAL SELECTED VARIABLES\n#           TEST - VALIDATION USED IN MODEL SELECTION\n#           IMPORTANCE - IMPORTANCE VALUES FROM SELECTED MODEL\n#           PARAMETERS - VARIABLES USED IN EACH TESTED MODEL\n#\n# NOTES: \n#        IF YOU WANT TO RUN CLASSIFICATION MAKE SURE Y IS A FACTOR\n#        OTHERWISE RF RUNS IN REGRESSION MODE\n#\n#        The mir scale option perfroms a row standardization and the se option performs\n#        normalization using The ?standard errors? of the permutation-based importance measure.\n#        Both options result in a 0-1 range but se summs to 1.  \n#                  mir = i/max(i)\n#                  se = (i / se) / ( sum(i) / se) \n#\n#  IMPORTANCE CANNONT BE FALSE AND IS SET IN THE FUNCTION, SO DO NOT USE IMPORTANCE FLAG\n#        \n#        For regression the model selection criteria is; largest %variation \n#        explained, smallest MSE, and fewest parameters. \n#         \n#        For classification; Smallest OOB error, smallest maximum within \n#        class error, and fewest parameters. \n#\n# REFERENCES:\n#    Evans, J.S. and S.A. Cushman (2009) Gradient Modeling of Conifer Species \n#      Using Random Forest. Landscape Ecology 5:673-683.\n#\n#    Murphy M.A., J.S. Evans, and A.S. Storfer (2010) Quantify Bufo boreas \n#      connectivity in Yellowstone National Park with landscape genetics. \n#      Ecology 91:252-261\n#\n#    Evans J.S., M.A. Murphy, Z.A. Holden, S.A. Cushman (2011). Modeling species \n#      distribution and change using Random Forests CH.8 in Predictive Modeling in \n#      Landscape Ecology eds Drew, CA, Huettmann F, Wiersma Y. Springer \n# \n# EXAMPLES: \n# # CLASSIFICATION\n#     data(iris)\n#     iris$Species <- as.factor(iris$Species) \n#\t ( rf.class <- rf.modelSel(iris[,1:4], iris[,\"Species\"], imp.scale=\"mir\") )\n#     ( rf.class <- rf.modelSel(iris[,1:4], iris[,\"Species\"], imp.scale=\"mir\", parsimony=0.03) ) \n#       vars <- rf.class$PARAMETERS[[3]]\n#     ( rf.fit <- randomForest(x=iris[,vars], y=iris[,\"Species\"]) )                           \n# # REGRESSION\n#     data(airquality)\n#     airquality <- na.omit(airquality)\n#     ( rf.regress <- rf.modelSel(airquality[,2:6], airquality[,1], imp.scale=\"se\") )\n#\t ( rf.regress <- rf.modelSel(airquality[,2:6], airquality[,1], imp.scale=\"se\", parsimony=0.03) )\n#       vars <- rf.regress$PARAMETERS[[3]]\n#         ( rf.fit <- randomForest(x=airquality[,vars], y=airquality[,1]) )\n# # REGRESSION - NOT RUN\t \n#    require(sp)\t \n#    data(meuse)\n#    meuse <- na.omit(meuse)\n#   ( rf.regress <- rf.modelSel(meuse[,4:14], meuse[,3], imp.scale=\"se\",\n#                               r=c(0.10,0.25,0.50,0.75,0.90)) )\t \n#    ( rf.regress <- rf.modelSel(meuse[,4:14], meuse[,3], imp.scale=\"se\", parsimony=0.03,\n#                                 r=c(0.10,0.25,0.50,0.75,0.90)) )\t \n#    \t                               \n# CONTACT: \n#     Jeffrey S. Evans \n#     Senior Landscape Ecologist \n#     The Nature Conservancy - Central Science\n#     Adjunct Faculty\n#     University of Wyoming\n#     Laramie, WY\n#     (970)672-6766\n#     jeffrey_evans@tnc.org\n##########################################################################\nrf.modelSel <- function(xdata, ydata, imp.scale=\"mir\", r=c(0.25, 0.50, 0.75),  \n                        final=FALSE, plot.imp=TRUE, parsimony=NULL, ...) \n  {\n if (!require (randomForest)) stop(\"randomForest PACKAGE MISSING\")\n rf.ImpScale <- function (x, scale=\"mir\") { \n  if (!inherits(x, \"randomForest\")) \n       stop(deparse(substitute(x)), \" Must be a randomForest object\")\n  if (x$type == \"regression\") {\n   if (is.null(x$importanceSD) == TRUE | \"%IncMSE\" %in% \n       names(as.data.frame(x$importance)) == FALSE)\n        stop(\"OBJECT DOES NOT CONTAIN PERMUTATED IMPORTANCE, PLEASE RUN \n              randomForest WITH importance=TRUE\")   \n\trf.imp <- x$importance[,\"%IncMSE\"]\n    rf.impSD <- x$importanceSD\n       rf.impSD[rf.impSD == 0] <- 0.000000001\t\n    if (scale == \"mir\") {\n      i <- rf.imp / max(rf.imp) \n\t\t}\t  \n    if (scale == \"se\") {\n\t  i <- ( rf.imp / rf.impSD ) / sum(rf.imp / rf.impSD, na.rm=TRUE)\t\t\t \n        }\n\t }\n  if (x$type == \"classification\" | x$type == \"unsupervised\") {\n   if (is.null(x$importanceSD) == TRUE | \"MeanDecreaseAccuracy\" %in% \n       names(as.data.frame(x$importance)) == FALSE)\n        stop(\"OBJECT DOES NOT CONTAIN PERMUTATED IMPORTANCE, PLEASE RUN \n       randomForest WITH importance=TRUE\") \n\trf.imp <- x$importance[,\"MeanDecreaseAccuracy\"]\n    rf.impSD <- x$importanceSD[,\"MeanDecreaseAccuracy\"]\n       rf.impSD[rf.impSD == 0] <- 0.000000001\t\n    if (scale == \"mir\") {\n      i <- rf.imp / max(rf.imp) \n\t\t}\t  \n    if (scale == \"se\") {\n\t  i <- ( rf.imp / rf.impSD ) / sum(rf.imp / rf.impSD, na.rm=TRUE)\t\t\t \n        }\n\t }\n \ti <- as.data.frame(i)\n\t  names(i) <- \"importance\" \n        row.names(i) <- names(rf.imp)\t\n   return( i )            \n }\n \nRFtype <- is.factor(ydata) #TEST FOR FACTOR IN Y \n##CLASSIFICATION##\nif (RFtype == \"TRUE\") {\n    model.vars <- list()\n    ln <- 0\n    rf.all <- randomForest(x=xdata, y=ydata, importance=TRUE, ...) \n      model.vars[[ln <- ln + 1]] <- rownames(rf.all$importance)  \n       class.errors <- as.data.frame(rf.all$err.rate)\n        class.errors <- na.omit(class.errors)  \n         class.errors[class.errors == NaN] <- 0\n          class.errors[class.errors == Inf] <- 1         \n        i <- vector()\n\t      for ( l in 2:nlevels(as.factor(names(class.errors))) ) {              \n            i <- append(i, median(class.errors[,l]))\n          }        \n        max.error = max(i) \n\timp <- rf.ImpScale(rf.all, scale=imp.scale) \n    results <- as.data.frame(array(0, dim=c( 0, 4 )))\n      x <- c(0, (median(rf.all$err.rate[,\"OOB\"]) * 100), max.error * 100, dim(xdata)[2] )\n    results <- rbind(results, x) \t \t \n     for (p in 1:length(r) ) {\n\t\t t = quantile(imp[,1], probs=r[p])\n         sel.imp <- subset(imp, importance >= t)\n           sel.vars <- rownames(sel.imp)\n     if (length( sel.vars ) > 1) {                             \n         xdata.sub <- xdata[,sel.vars]       \n      rf.model <- randomForest(x=xdata.sub, y=ydata, importance=TRUE)          \n           class.errors <- as.data.frame(rf.model$err.rate)\n            class.errors <- na.omit(class.errors)  \n             class.errors[class.errors == NaN] <- 0\n              class.errors[class.errors == Inf] <- 1      \n        i <- as.vector(array(0, dim=c((0),(1))))\n       for ( l in 2:nlevels(as.factor(names(class.errors))) )\n          {\n          x.bar <- mean(class.errors[,l])              \n            i <- as.vector(append(i, x.bar, after=length(i) ))\n            }        \n         max.error = max(i[2:length(i)] )     \n         x <- c(t, median(rf.model$err.rate[,1]) * 100, max.error * 100, length(sel.vars) )\n         results <- rbind(results, x)\n\t\t  model.vars[[ln <- ln + 1]] <- rownames(rf.model$importance)\n         }\n        }\n  names(results) <- c(\"THRESHOLD\", \"OOBERROR\", \"CLASS.ERROR\", \"NPARAMETERS\")\n  results <- results[order(results$CLASS.ERROR, results$OOBERROR, results$NPARAMETERS),]\n    if (is.null(parsimony) == FALSE) { \n\t  if(parsimony < 0.00000001 | parsimony > 0.9) stop( \"parsomony MUST RANGE 0-1\")\n        oob <- \"TRUE\"\n        for(i in 2:nrow(results)) {\n          if( abs((results[i,][2] - results[1,][2] ) / results[1,][2]) <= parsimony  &\n              abs( (results[i,][3] - results[1,][3] ) / results[1,][3] ) <= parsimony ) {\n            oob <- append(oob, \"TRUE\")\n        \t  } else {\n        \toob <- append(oob, \"FALSE\")\n            }\n            final <- results[which( oob == \"TRUE\" ),]\n        \t  final <- final[final$NPARAMETERS == min(final$NPARAMETERS) ,]$THRESHOLD\n        }\n          } else {\t\t\n            final <- as.vector(results[,\"THRESHOLD\"])[1]\n        }\t\n      sel.imp <- subset(imp, importance >= final)    \n        sel.vars <- rownames(sel.imp)\n          sel.post=which( results$NPARAMETERS == length(sel.vars) ) \n      results <- rbind(results[sel.post,],results[-sel.post,]) \t\n  } # END OF CLASSIFICATION\n  \n##REGRESSION## \nif (RFtype == \"FALSE\") {\n    model.vars <- list()\n      ln <- 0      \n    rf.all <- randomForest(x=xdata, y=ydata, importance=TRUE, ...) \n\t  model.vars[[ln <- ln + 1]] <- rownames(rf.all$importance)  \n\t   imp <- rf.ImpScale(rf.all, scale=imp.scale) \n      results <- as.data.frame(array(0, dim=c( 0, 4 )))\n     x <- c(0, (median(rf.all$rsq)), mean(rf.all$mse), dim(xdata)[2] )\n     results <- rbind(results, x)     \n   for (p in 1:length(r) ) {\n        t = quantile(imp[,1], probs=r[p])\t\t \n        sel.vars <- rownames(subset(imp, importance >= t))  \n     if (length( sel.vars ) > 1) {                             \n      xdata.sub <- as.data.frame(xdata[,sel.vars]) \n      rf.model <- randomForest(x=xdata.sub, y=ydata, importance=TRUE, ...)          \n      x <- c(t, (median(rf.model$rsq)), mean(rf.model$mse), length(sel.vars) )\n      results <- rbind(results, x)\n\t     model.vars[[ln <- ln + 1]] <- rownames(rf.model$importance)\n      }\n    }\n   names(results) <- c(\"THRESHOLD\", \"VAREXP\", \"MSE\", \"NPARAMETERS\")\n     results <- results[order(-results$VAREXP, results$MSE, results$NPARAMETERS),]  \n    if (!is.null(parsimony)) {\n      if(parsimony < 0.00000001 | parsimony > 0.9) stop( \"parsomony MUST RANGE 0-1\")\t\n        oob <- \"TRUE\"\n        for(i in 2:nrow(results)) {\n          if( abs((results[i,][2] - results[1,][2] ) / results[1,][2]) <= parsimony  &\n              abs( (results[i,][3] - results[1,][3] ) / results[1,][3] ) <= parsimony ) {\n            oob <- append(oob, \"TRUE\")\n        \t  } else {\n        \toob <- append(oob, \"FALSE\")\n            }\n            final <- results[which( oob == \"TRUE\" ),]\n        \t  final <- final[final$NPARAMETERS == min(final$NPARAMETERS) ,]$THRESHOLD\n        }\n          } else {\t\t\n            final <- as.vector(results[,\"THRESHOLD\"])[1]\n        }\t\n      sel.imp <- subset(imp, importance >= final)    \n        sel.vars <- rownames(sel.imp)\n        sel.post=which( results$NPARAMETERS == length(sel.vars) ) \n      results <- rbind(results[sel.post,],results[-sel.post,]) \t\t\t\n   } # END OF REGRESSION \n   \n    if (plot.imp == TRUE) {\n        if (imp.scale==\"mir\") {lable=\"Row Standardization Variable Importance\"} \t\n\t\t  if (imp.scale==\"se\") {lable=\"Standardized Error Variable Importance\"}\n\t  p <- as.matrix(subset(imp, importance >= final))    \n       ord <- rev(order(p[,1], decreasing=TRUE)[1:dim(p)[1]])  \n       dotchart(p[ord,1], main=lable, pch=19)\n    }\n\t\n    if (final == TRUE) {\n       sub.xdata <- xdata[,sel.vars]  #SUBSET VARIABLES\n        rf.final <- randomForest(x=sub.xdata, y=ydata, importance=TRUE, ...)           \n      ( list(MODEL=rf.final, SELVARS=sel.vars, TEST=results, IMPORTANCE=sel.imp, PARAMETERS=model.vars) )      \n         } else {\n      ( list(SELVARS=sel.vars, TEST=results, IMPORTANCE=sel.imp, PARAMETERS=model.vars) ) \n    }     \n }\n\n######################################################################################\n# PROGRAM: rf.ClassBalance (FOR CLASSIFICATION)\n# USE: CREATES A BALANCED SAMPLE IN A RANDOM FORESTS CLASSIFICATION MODEL \n# REQUIRES: R 2.15.0, randomForest 4.6-5 (CURRENT TESTED VERSIONS) \n#                                                                                                                                                                                                     \n# ARGUMENTS:  \n#       ydata      RESPONSE VARIABLE  (i.e., [,2] or [,\"SPP\"] )                        \n#       xdata      INDEPENDENT VARIABLES(S)  (i.e., [,3:14] or [3:ncol(data)] )\n#       p          P-VALUE OF COVARIANCE CONVERGENCE TEST (DO NOT RECCOMEND CHANGING)\n#       cbf        FACTOR USED TO TEST IF MODEL IS IMBALANCED, DEFAULT IS SIZE OF \n#                    MINORITY CLASS * 3                                              \n#       ...        ADDITIONAL ARGUMENTS TO PASS TO RANDOM FOREST                          \n# \n# VALUE:  \n#      A LIST OBJECT WITH RF MODEL OBJECT, CUMMLIATIVE OOB ERROR,        \n#        CUMMLIATIVE CONFUSION MATRIX, AND PERCENT CORRECT CLASSIFIED  \n#\n# NOTES:\n#     RUNS MODEL WITH RANDOM SUBSET OF MAJORITY CLASS UNTIL                   \n#       COVARIANCE CONVERGES TO FULL DATA. PREDECTION IS BASED ON                 \n#       COMBINING SUBSET MODELS TO CREATE FINAL ENSEMBLE\n#\n# REFERENCES:\n#    Evans, J.S. and S.A. Cushman (2009) Gradient Modeling of Conifer Species \n#      Using Random Forest. Landscape Ecology 5:673-683.\n#\n#    Evans J.S., M.A. Murphy, Z.A. Holden, S.A. Cushman (2011). Modeling species \n#      distribution and change using Random Forests CH.8 in Predictive Modeling in \n#      Landscape Ecology eds Drew, CA, Huettmann F, Wiersma Y. Springer \n#                                                                       \n# EXAMPLES: \n#      rfClassBalance(ydata=data[,1], xdata=data[,3:ncol(data)], ntree=100)       \n#                                                                                       \n# CONTACT:\n#     Jeffrey S. Evans\n#     Senior Landscape Ecologist  \n#     The Nature Conservancy\n#     Central Science/DbyD\n#     Affiliate Assistant Professor\n#     Environment and Natural Resources\n#     University of Wyoming\n#     Laramie, WY 82070 \n#     jeffrey_evans@tnc.org\n#     (970) 672-6766\n######################################################################################\nrfClassBalance <- function (ydata, xdata, p=0.005, cbf=3,...) \n {\n if (!require (randomForest)) stop(\"randomForest PACKAGE MISSING\")\n  if (  class(ydata) != \"factor\" ) { ydata <- as.factor(ydata) }\n  CompCov <- function(m1, m2, pVal=p) {\n       k = 2\n        p = 2\n         n1 = dim(m1)[1]\n          n2 = dim(m2)[1] \n           n = n1 + n2\n            s1 <- crossprod(m1[1:dim(m1)[1]])\n             s2 <- crossprod(m2[1:dim(m2)[1]])\n              c1 = (1/(n1-1))*s1\n              c2 = (1/(n2-1))*s2\n             c = (s1+s2)/(n-k)\n            d = det(c)\n            d1 = det(c1)\n           d2 = det(c2) \n          m = ( (n-k)*log(d) ) - ( (n1-1)*log(d1) + (n2-1)*log(d2) )\n         h = 1-((2*p*p+3*p-1) / (6*(p+1)*(k-1)) * (1 / (n1-1)+1 / (n2-1)+1 / (n-k)))\n        chi = round(abs(m*h),digits=6)\n       df = p*(p+1)*(k-1)/2\n       print( paste(\"EQUIVALENCE p\", chi, sep=\": \") )\n          if ( (chi <= pVal ) == TRUE & (i > 2) |  (i > 20)  == TRUE ) { \n               ( \"TRUE\" )\n                  } else {\n               ( \"FALSE\" ) \n             }\n         }  \t\t \n    y <- ydata\n    x <- xdata  \t\t \t\t \n    class.ct <- as.numeric()\t\t \n      for(i in 1:nlevels(y)) {\n        class.ct <- append(class.ct, length(which(y==levels(y)[i])), \n    \t                   after=length(class.ct) )\n        }\n        maj.post <- which.max(class.ct)\n    \t  maj.class <- levels(ydata) [maj.post]\n        min.post <- which.min(class.ct)\n    \t  min.class <- levels(ydata) [min.post]\n    \t\t\n    if ( ( class.ct[maj.post] <= class.ct[min.post] * cbf ) == TRUE) \n            stop(\"CLASSES ARE BALANCED!\")      \n    tmp.data <- data.frame(y, x)\n\t   majority <- tmp.data[tmp.data[,\"y\"] == maj.class ,]       \n       minority <- tmp.data[tmp.data[,\"y\"] == min.class ,]    \n\t   all.cov <- cov(majority[,names(x)])     \n\t  test <- as.data.frame(array(0, dim=c( 0, dim(tmp.data)[2] )))\n        names(test) <- names(majority) \n     if ( !is.na(match(\"rf.model\",ls()))) rm(rf.model)\n        n <- dim(minority)[1]*2                 \n  i=0  \n    converge = c(\"FALSE\")  \n     while (converge != \"TRUE\" )\n       {\n       i=i+1\n        ns <- sample(1:nrow(majority), n) \n        class.sample <- majority[ns, ]\n          mdata <- rbind(minority, class.sample)   \n        if (  class(mdata[,1]) != \"factor\" ) \n                   { mdata[,1] <- as.factor(mdata[,1]) }\n        if ( !is.na(match(\"rf.model\",ls()))) {               \n            rf.fit <- randomForest(x=mdata[,2:ncol(mdata)], y=mdata[,1])                           \n            rf.model <- combine(rf.fit, rf.model)           \n               OOB <- ( OOB + median(rf.fit$err.rate[,1]) ) \n               CM <- (CM + rf.fit$confusion)                 \n               confusion <- confusion + rf.fit$confusion \n               } else {\n            rf.model <- randomForest(x=mdata[,2:ncol(mdata)], y=mdata[,1])  \n               OOB <- median(rf.model$err.rate[,1]) \n               CM <- rf.model$confusion           \n               confusion <- rf.model$confusion                          \n         }\n      test <- rbind(test, class.sample)    \n         test.cov <- cov( test[,names(x)] )\n         converge <- CompCov(all.cov, test.cov)  \n  }\n    OOB <- OOB / i\n    CM[,3] <- CM[,3] / i\n    PCC <- ( sum(diag(CM))/sum(CM) ) * 100\n   list( MODEL=rf.model, OOB_ERROR=OOB, CONFUSION=CM, PCT_CC=PCC )\n}\n\n##########################################################################\n# PROGRAM: rf.Permutation (FOR REGRESSION)\n# USE: RANDOM PERMUTATION TO TEST SIGNIFICANCE OF randomForest REGRESSION MODEL\n# REQUIRES: >= R 2.15.0, randomForest 4.6-7 \n#           \n# ARGUMENTS: \n#      x         DEPENDENT VARABLE(S) TO USE IN MODEL\n#      y         DEPENDENT VARIABLE TO USE IN MODEL\n#      p         p VALUE TO TEST FOR MODEL SIGNIFICANCE\n#      q         QUANTILE THRESHOLD FOR PLOT\n#      nperm     NUMBER OF PERMUTATIONS\n#      plot      SHOULD THE RESULTS BE PLOTTED (DOTTED LINE REPRESENT TEST p-VALUE)\n#      ...       ADDITIONAL randomForest ARGUMENTS \n#\n# VALUE:\n#    A LIST WITH THE FOLLOWING OBJECTS\n#       RandRsquare      VECTOR OF RANDOM R-SQUARE VALUES\n#       Rsquare          R SQUARE OF TRUE MODEL  \n#       Accept           IS THE MODEL SIGNIFICANT AT SPECIFIED p VALUE\n#       TestQuantile     QUANTILE THRESHOLD USED IN SIGNIFICANCE PLOT\n#       pValueThreshold  SIGNIFICANCE VALUE\n#       pValue           P VALUE OF RANDOMIZATIONS\n#       nPerm            NUMBER OF PERMUTATIONS          \n#\n# REFERENCES:\n#    Murphy M.A., J.S. Evans, and A.S. Storfer (2010) Quantify Bufo boreas \n#      connectivity in Yellowstone National Park with landscape genetics. \n#      Ecology 91:252-261\n#\n#    Evans J.S., M.A. Murphy, Z.A. Holden, S.A. Cushman (2011). Modeling species \n#      distribution and change using Random Forests CH.8 in Predictive Modeling in \n#      Landscape Ecology eds Drew, CA, Huettmann F, Wiersma Y. Springer \n# \n# EXAMPLES: \n#    require(randomForest)\n#    data(airquality)\n#    airquality <- na.omit(airquality)\n#      ( rf.test <- rf.Permutation(x=airquality[,2:6], y=airquality[,1], nperm=999) )\n#                               \n# CONTACT: \n#     Jeffrey S. Evans \n#     Senior Landscape Ecologist \n#     The Nature Conservancy - Central Science\n#     Adjunct Faculty\n#     University of Wyoming\n#     Laramie, WY\n#     (970)672-6766\n#     jeffrey_evans@tnc.org\n##########################################################################\nrf.Permutation <- function(x, y, q=0.99, p=0.05, nperm=999, plot=TRUE, ...) {\n  if (!require (randomForest)) stop(\"randomForest PACKAGE MISSING\")\n    if (is.factor(y)) stop(\"y CANNOT BE A FACTOR\") \n      rf.test <- randomForest(x=x, y=y, ...)\n\t    test.rsq <- median(rf.test$rsq)\n\trand.dist <- vector() \n      for( i in 1:nperm) {\t\n        rand.y <- sample(y, length(y)) \n          rf.test <- randomForest(x=x, y=rand.y, ...)\n            rand.dist <- append(rand.dist, median(rf.test$rsq)) \n        }\t\n       Pval <- function(x, test, nperm) { \n         if ( length( x[x >= test] ) < 1 ) { \n\t           error = 1 \n\t         } else { \n\t   \t    error = length( x[x >= test] ) + 1\n\t   \t   }\t\n          return( error / nperm )\n        }\t\t\t\t\n\t  if( plot == TRUE) { \n\t    den=density(rand.dist)\n          den$y <- den$y/max(den$y)\t\t\n\t        plot(den, type=\"n\", xlim=c(min(rand.dist), 1), xlab=\"R-square\", ylab=\"\",  \n\t  \t         main=\"Distribution of randomized models\")\n                   polygon(den, col=\"blue\")\n                     abline(v=test.rsq, col=\"black\", lwd=1.5, lty=2)\n\t\t\t\t\t abline(v=quantile(rand.dist,p=q),lwd=1.5, lty=2, col=\"red\") \n              legend(\"topright\", c(\"model\", \"null\"), bg=\"white\",  \n\t\t             col=c(\"black\",\"red\"), lty=c(2,2), lwd=c(1.5,1.5) )\t\t\t\t   \n\t    }\n\t  pValue=round(Pval(x=rand.dist, test=test.rsq, nperm=nperm), digits=6)\t\n\tif( pValue <= p ) accept=TRUE else accept=FALSE \n      if (accept == TRUE) accept <- paste(\"MODEL SIGNIFICANT AT p=\", pValue, sep=\"\" ) \n\t    if (accept == FALSE) accept <- paste(\"MODEL NOT SIGNIFICANT AT p= \", pValue, sep=\"\" )\n    print(accept)\t\t\n  return( list(RandRsquare=rand.dist, Rsquare=test.rsq, Accept=accept, TestQuantile=q, \n               pValueThreshold=p, pValue=pValue, nPerm=nperm) )\n} \n\n##########################################################################\n# PROGRAM: PlotROC\n# USE: PLOTS A ROC FOR A BINARY PROBLEM AND REPORTS VALIDATION STATS\n# REQUIRES: TWO ORDERED VECTORS OF OBSERVED AND PREDICTED VALUES\n#               PACKAGE \"ROCR\"\n#\n# ARGS: predictedValues      Predicted values\n#       actualValues         Observed values\n#       cutoff               Method to calculate cutoff\n#       cutoffValue          Critical cutoff value\n#       colorize             Plot in color\n#       title                Plot title\n#       summaryFile          Object contaning validation statistics\n#       bg                   Background plot color\n#\n# EXAMPLE: PlotROC(model[,\"PRED\"], model[,\"OBS\"], cutoff=\"automatic\", .title=\"ROC PLOT\" )\n#              \n# CONTACT: \n#     Jeffrey S. Evans, Ph.D.\n#     Senior Landscape Ecologist  \n#     The Nature Conservancy\n#     Central Science/DbyD\n#     Affiliate Assistant Professor\n#     Environment and Natural Resources\n#     University of Wyoming\n#     Laramie, WY 82070 \n#     jeffrey_evans@tnc.org\n#     (970) 672-6766\n##########################################################################\nPlotROC <- function(predictedValues, actualValues, cutoff=\"automatic\", cutoffValue=NULL, \n                    colorize=TRUE, .title=NULL, summaryFile=NULL, bg=\"white\")\n{\n    require(ROCR)\n    pred <- prediction(predictedValues, actualValues)\n    \n    # Create the ROC performance object. \n    perf <- performance(pred, \"tpr\", \"fpr\")\n    \n    # Calculate model summary statistics.\n    nLabel <- min(actualValues)                   \n    pLabel <- max(actualValues)                   \n    \n    auc <- performance(pred, \"auc\")@y.values[[1]]\n    \n    if ((nLabel == 0 || nlabel == 1) && (pLabel == 0 || pLabel == 1))\n        mxe <- performance(pred, \"mxe\")@y.values[[1]]\n    else\n        mxe <- NA\n        \n    prbe <- unlist(performance(pred, \"prbe\")@y.values)\n    if (length(prbe) > 0)\n        prbe <- prbe[length(prbe)]\n    else\n        prbe <- NA\n        \n    if (is.numeric(nLabel))\n        rmse <- performance(pred, \"rmse\")@y.values[[1]]\n    else\n        rmse <- NA\n\n    messages = vector(mode=\"character\")\n\n    messages = append(messages, \"Model summary statistics:\")\n    messages = append(messages, \"\")\n    messages = append(messages, sprintf(\"Area under the ROC curve (auc)           = %f\", auc))\n    if (!is.na(mxe))\n        messages = append(messages, sprintf(\"Mean cross-entropy (mxe)                 = %f\", mxe))\n    messages = append(messages, sprintf(\"Precision-recall break-even point (prbe) = %f\", prbe))\n    messages = append(messages, sprintf(\"Root-mean square error (rmse)            = %f\", rmse))\n    \n    # If asked us to calculate the cutoff, calculate it.\n    if (cutoff == \"automatic\")\n    {\n        distFromPerfect <- sqrt(unlist(perf@x.values)^2 + (1 - unlist(perf@y.values))^2)\n        cutoffValue <- unlist(perf@alpha.values)[which.min(distFromPerfect)]\n    }\n    \n    # If there is a cutoff, calculate the contingency table. \n    if (cutoff != \"none\")\n    {\n        tn = length(which((predictedValues < cutoffValue) & (actualValues == nLabel)))\n        fn = length(which((predictedValues < cutoffValue) & (actualValues != nLabel)))\n        tp = length(which((predictedValues >= cutoffValue) & (actualValues == pLabel)))\n        fp = length(which((predictedValues >= cutoffValue) & (actualValues != pLabel)))\n        \n        messages = append(messages, \"\")\n        messages = append(messages, sprintf(\"Contingency table for cutoff = %f:\", cutoffValue))\n        messages = append(messages, \"\")\n        messages = append(messages, \"             Actual P  Actual N     Total\")\n        messages = append(messages, sprintf(\"Predicted P %9i %9i %9i\", tp, fp, tp+fp))\n        messages = append(messages, sprintf(\"Predicted N %9i %9i %9i\", fn, tn, tn+fn))\n        messages = append(messages, sprintf(\"      Total %9i %9i %9i\", tp+fn, fp+tn, tp+fn+fp+tn))\n        messages = append(messages, \"\")\n\n        tn = as.double(tn)\n        fn = as.double(fn)\n        tp = as.double(tp)\n        fp = as.double(fp)\n        acc = (tp+tn)/(tp+fp+tn+fn)\n\n        messages = append(messages, sprintf(\"Accuracy (acc)                                = %f\", acc))\n        messages = append(messages, sprintf(\"Error rate (err)                              = %f\", (fp+fn)/(tp+fp+tn+fn)))\n        messages = append(messages, sprintf(\"Rate of positive predictions (rpp)            = %f\", (tp+fp)/(tp+fp+tn+fn)))\n        messages = append(messages, sprintf(\"Rate of negative predictions (rnp)            = %f\", (tn+fn)/(tp+fp+tn+fn)))\n        messages = append(messages, \"\")\n        messages = append(messages, sprintf(\"True positive rate (tpr, or sensitivity)      = %f\", tp/(tp+fn)))\n        messages = append(messages, sprintf(\"False positive rate (fpr, or fallout)         = %f\", fp/(fp+tn)))\n        messages = append(messages, sprintf(\"True negative rate (tnr, or specificity)      = %f\", tn/(fp+tn)))\n        messages = append(messages, sprintf(\"False negative rate (fnr, or miss)            = %f\", fn/(tp+fn)))\n        messages = append(messages, \"\")\n        messages = append(messages, sprintf(\"Positive prediction value (ppv, or precision) = %f\", tp/(tp+fp)))\n        messages = append(messages, sprintf(\"Negative prediction value (npv)               = %f\", tn/(tn+fn)))\n        messages = append(messages, sprintf(\"Prediction-conditioned fallout (pcfall)       = %f\", fp/(tp+fp)))\n        messages = append(messages, sprintf(\"Prediction-conditioned miss (pcmiss)          = %f\", fn/(tn+fn)))\n        messages = append(messages, \"\")\n        messages = append(messages, sprintf(\"Matthews correlation coefficient (mcc)        = %f\", (tp*tn - fp*fn)/sqrt((tp+fn)*(fp+tn)*(tp+fp)*(fn+tn))))\n        messages = append(messages, sprintf(\"Odds ratio (odds)                             = %f\", (tp*tn)/(fn*fp)))\n        messages = append(messages, sprintf(\"SAR                                           = %f\", (acc + auc + rmse)/3))\n    }\n    else\n    {\n        cutoffValue = NA\n        tp = NA\n        fp = NA\n        tn = NA\n        fn = NA\n    }\n    \n    # Output the messages, optionally to the summaryFile.\n    writeLines(\"\")\n    writeLines(messages)\n    writeLines(\"\")\n    \n    if (!is.null(summaryFile))\n        writeLines(messages, summaryFile)\n    \n    # Create the ROC plot.\n    plot(perf, colorize=colorize, lwd=5, main=.title)\n    abline(0, 1, lty=2)\n    if (cutoff != \"none\")\n    {\n        tpr = tp/(tp+fn)\n        fpr = fp/(fp+tn)\n        if (colorize)\n            points(x=fpr, y=tpr, cex=1.5, lwd=2)\n        else\n            points(x=fpr, y=tpr, pch=21, cex=1.5, lwd=2, bg=bg)\n        text(x=fpr+0.01, y=tpr-0.01, labels=sprintf(\"Cutoff = %f\", cutoffValue), adj=c(0,1))\n    }\n    \n    # Return successfully.\n    return(c(cutoffValue, tp, fp, fn, tn, auc, mxe, prbe, rmse))\n}\n\n##########################################################################\n# PROGRAM: ClassificationValidation.R\n# USE: CALCULATES VALIDATION STATISTICS ON CLASSIFICATION MODELS\n# REQUIRES: A CONFUSION MATRIX OR VECTOR(s) OF OBSERVED AND PREDICTED-CLASS 1...n\n#\n# Default method for obs/pred data\n# confusionMatrix(data, reference, positive = NULL, dnn = c(\"Prediction\", \"Reference\"), \n#                prevalence = NULL, ...)\n#\n# method for class 'table':\n# confusionMatrix(data, positive = NULL, prevalence = NULL, ...)\n#\n# ARGUMENTS: \n# data - a factor of predicted classes (for the default method) or an object of class table.\n# reference - a factor of classes to be used as the true results\n# positive - an optional character string for the factor level that corresponds to a \"positive\" \n#            result (if that makes sense for your data). If there are only two factor levels, \n#            the first level will be used as the \"positive\" result.\n# dnn - a character vector of dimnames for the table\n# prevalence - a numeric value or matrix for the rate of the \"positive\" class of the data. \n#              When data has two levels, prevalence should be a single numeric value. Otherwise, \n#              it should be a vector of numeric values with elements for each class. The vector \n#              should have names corresponding to the classes.\n#\n# DETAILS\n#   For two class problems, the sensitivity, specificity, positive predictive value and negative \n#   predictive value is calculated using the positive argument. Also, the prevalence of the \"event\" \n#   is computed from the data (unless passed in as an argument), the detection rate (the rate of true \n#   events also predicted to be events) and the detection prevalence (the prevalence of predicted events).\n#\n# 2x2 table with notation\t\n#  Predicted \t  Pres   Abs\n#         Pres \t  A \t  B\n#         Abs     C \t  D\n#\n# Formulas:\n#   Sensitivity = A/(A+C)\n#   Specificity = D/(B+D)\n#   Prevalence = (A+C)/(A+B+C+D)\n#   PPV = (sensitivity * Prevalence)/((sensitivity*Prevalence) + ((1-specificity)*(1-Prevalence)))\n#   NPV = (specificity * (1-Prevalence))/(((1-sensitivity)*Prevalence) + ((specificity)*(1-Prevalence)))\n#   Detection Rate = A/(A+B+C+D)\n#   Detection Prevalence = (A+B)/(A+B+C+D)\n#\n#   The overall accuracy and unweighted Kappa statistic are calculated. The overall accuracy rate is \n#   computed along with a 95 percent confidence interval for this rate (using binom.test) and a one-sided \n#   test to see if the accuracy is better than the \"no information rate,\" which is taken to be the largest \n#   class percentage in the data. For more than two classes, these results are calculated comparing each \n#   factor level to the remaining levels (i.e. a \"one versus all\" approach).  \n#\n# EXAMPLES:\n#  Default method using two columns\n#   confusionMatrix(data[,\"OBSERVED\"], data[,\"PREDICTED\"])\n#\n#  Class \"table\" for use with defined confusion matrix \n#    confusion = as.table(rbind(c(505, 122),c(6, 23)))\n#      rownames(confusion) <- c(\"ABS\",\"PRES\")\n#      colnames(confusion) <- c(\"ABS\",\"PRES\")\n#    confusionMatrix(confusion)\n#      \n#  Using two values resulting from Boolean statment\n#    agree=25000\n#    disagree=5000\n#      confusion = as.table(rbind(c(agree, disagree),c(disagree, agree)))\n#        rownames(confusion) <- c(\"AGREE\",\"DISAGREE\")\n#        colnames(confusion) <- c(\"AGREE\",\"DISAGREE\")\n#    confusionMatrix(confusion)\n#\n# CONTACT: \n#     Jeffrey S. Evans, Ph.D.\n#     Senior Landscape Ecologist  \n#     The Nature Conservancy\n#     Central Science/DbyD\n#     Affiliate Assistant Professor\n#     Environment and Natural Resources\n#     University of Wyoming\n#     Laramie, WY 82070 \n#     jeffrey_evans@tnc.org\n#     (970) 672-6766\n##########################################################################\nposPredValue <- function(data, ...){\n    UseMethod(\"posPredValue\")\n  }\n\"posPredValue.default\" <- function(data, reference, positive = levels(reference)[1], prevalence = NULL, ...)\n{\n  if(!is.factor(reference) | !is.factor(data)) \n    stop(\"inputs must be factors\")\n  \n  if(length(unique(c(levels(reference), levels(data)))) != 2)\n    stop(\"input data must have the same two levels\")\n  \n  lvls <- levels(data) \n  if(is.null(prevalence)) prevalence <- mean(reference == positive)\n  sens <- sensitivity(data, reference, positive)\n  spec <- specificity(data, reference, lvls[lvls != positive])\n  (sens * prevalence)/((sens*prevalence) + ((1-spec)*(1-prevalence)))\n\n}\n\n\"posPredValue.table\" <- function(data, positive = rownames(data)[1], prevalence = NULL, ...)\n{\n  ## \"truth\" in columns, predictions in rows\n  if(!all.equal(nrow(data), ncol(data))) stop(\"the table must have nrow = ncol\")\n  if(!all.equal(rownames(data), colnames(data))) stop(\"the table must the same groups in the same order\")\n  if(nrow(data) > 2)\n    {\n      tmp <- data\n      data <- matrix(NA, 2, 2)\n      colnames(data) <- rownames(data) <- c(\"pos\", \"neg\")\n      posCol <- which(colnames(tmp) %in% positive)\n      negCol <- which(!(colnames(tmp) %in% positive))\n      data[1, 1] <- sum(tmp[posCol, posCol])\n      data[1, 2] <- sum(tmp[posCol, negCol])\n      data[2, 1] <- sum(tmp[negCol, posCol])      \n      data[2, 2] <- sum(tmp[negCol, negCol])\n      data <- as.table(data)\n      positive <- \"pos\"\n      rm(tmp)\n    }\n  negative <- colnames(data)[colnames(data) != positive]\n  if(is.null(prevalence)) prevalence <- sum(data[, positive])/sum(data)\n  \n  sens <- sensitivity(data, positive)\n  spec <- specificity(data, negative)\n    (sens * prevalence)/((sens*prevalence) + ((1-spec)*(1-prevalence)))\n}\n\n\"posPredValue.matrix\" <- function(data, positive = rownames(data)[1], prevalence = NULL, ...)\n{\n  data <- as.table(data)\n  posPredValue.table(data, prevalence = prevalence)\n}\n\nnegPredValue <- function(data, ...){\n    UseMethod(\"negPredValue\")\n  }\n\n\"negPredValue.default\" <- function(data, reference, negative = levels(reference)[2], prevalence = NULL, ...)\n{\n   if(!is.factor(reference) | !is.factor(data)) \n      stop(\"input data must be a factor\")\n   \n   if(length(unique(c(levels(reference), levels(data)))) != 2)\n      stop(\"input data must have the same two levels\")   \n\n   lvls <- levels(data) \n   if(is.null(prevalence)) prevalence <- mean(reference == lvls[lvls != negative])\n   sens <- sensitivity(data, reference, lvls[lvls != negative])\n   spec <- specificity(data, reference, negative)\n   (spec * (1-prevalence))/(((1-sens)*prevalence) + ((spec)*(1-prevalence)))\n}\n\n\"negPredValue.table\" <- function(data, negative = rownames(data)[-1], prevalence = NULL, ...)\n{\n  ## \"truth\" in columns, predictions in rows\n  if(!all.equal(nrow(data), ncol(data))) stop(\"the table must have nrow = ncol\")\n  if(!all.equal(rownames(data), colnames(data))) stop(\"the table must the same groups in the same order\")\n\n  if(nrow(data) > 2)\n    {\n      tmp <- data\n      data <- matrix(NA, 2, 2)\n      \n     colnames(data) <- rownames(data) <- c(\"pos\", \"neg\")\n      negCol <- which(colnames(tmp) %in% negative)\n      posCol <- which(!(colnames(tmp) %in% negative))\n      \n      data[1, 1] <- sum(tmp[posCol, posCol])\n      data[1, 2] <- sum(tmp[posCol, negCol])\n      data[2, 1] <- sum(tmp[negCol, posCol])      \n      data[2, 2] <- sum(tmp[negCol, negCol])\n      data <- as.table(data)\n      negative <- \"neg\"\n      rm(tmp)\n    }\n\n  positive <- colnames(data)[colnames(data) != negative]\n  if(is.null(prevalence)) prevalence <- sum(data[, positive])/sum(data)\n  \n  sens <- sensitivity(data, positive)\n  spec <- specificity(data, negative)\n  (spec * (1-prevalence))/(((1-sens)*prevalence) + ((spec)*(1-prevalence)))\n\n}\n\n\"negPredValue.matrix\" <- function(data, negative = rownames(data)[-1], prevalence = NULL, ...)\n{\n  data <- as.table(data)\n  negPredValue.table(data, prevalence = prevalence)\n}\n\nsensitivity <- function(data, ...){\n    UseMethod(\"sensitivity\")\n  }\n\n\"sensitivity.default\" <- function(data, reference, positive = levels(reference)[1], ...)\n{\n  if(!is.factor(reference) | !is.factor(data)) \n    stop(\"inputs must be factors\")\n\n  ## todo: relax the =2 constraint and let ngative length be > 2\n  if(length(unique(c(levels(reference), levels(data)))) != 2)\n    stop(\"input data must have the same two levels\")\n  \n  numer <- sum(data %in% positive & reference %in% positive)\n  denom <- sum(reference %in% positive)\n  sens <- ifelse(denom > 0, numer / denom, NA)\n  sens\n}\n\n\"sensitivity.table\" <- function(data, positive = rownames(data)[1], ...)\n{\n  ## \"truth\" in columns, predictions in rows\n  if(!all.equal(nrow(data), ncol(data))) stop(\"the table must have nrow = ncol\")\n  if(!all.equal(rownames(data), colnames(data))) stop(\"the table must the same groups in the same order\")\n\n  if(nrow(data) > 2)\n    {\n      tmp <- data\n      data <- matrix(NA, 2, 2)\n      \n      colnames(data) <- rownames(data) <- c(\"pos\", \"neg\")\n      posCol <- which(colnames(tmp) %in% positive)\n      negCol <- which(!(colnames(tmp) %in% positive))\n      \n      data[1, 1] <- sum(tmp[posCol, posCol])\n      data[1, 2] <- sum(tmp[posCol, negCol])\n      data[2, 1] <- sum(tmp[negCol, posCol])      \n      data[2, 2] <- sum(tmp[negCol, negCol])\n      data <- as.table(data)\n      positive <- \"pos\"\n      rm(tmp)\n    }\n\n  numer <- sum(data[positive, positive])\n  denom <- sum(data[, positive])\n  sens <- ifelse(denom > 0, numer / denom, NA)\n  sens\n}\n\n\"sensitivity.matrix\" <- function(data, positive = rownames(data)[1], ...)\n{\n  data <- as.table(data)\n  sensitivity.table(data)\n}\n\nspecificity <- function(data, ...){\n    UseMethod(\"specificity\")\n  }\n\n\"specificity.default\" <- function(data, reference, negative = levels(reference)[-1], ...)\n{\n   if(!is.factor(reference) | !is.factor(data)) \n      stop(\"input data must be a factor\")\n\n   ## todo: relax the =2 constraint and let ngative length be > 2\n   if(length(unique(c(levels(reference), levels(data)))) != 2)\n      stop(\"input data must have the same two levels\")   \n   \n   numer <- sum(data %in% negative & reference %in% negative)\n   denom <- sum(reference %in% negative)\n   spec <- ifelse(denom > 0, numer / denom, NA)  \n   spec\n}\n\n\"specificity.table\" <- function(data, negative = rownames(data)[-1], ...)\n{\n  ## \"truth\" in columns, predictions in rows\n  if(!all.equal(nrow(data), ncol(data))) stop(\"the table must have nrow = ncol\")\n  if(!all.equal(rownames(data), colnames(data))) stop(\"the table must the same groups in the same order\")\n\n  if(nrow(data) > 2)\n    {\n      tmp <- data\n      data <- matrix(NA, 2, 2)\n      \n      colnames(data) <- rownames(data) <- c(\"pos\", \"neg\")\n      negCol <- which(colnames(tmp) %in% negative)\n      posCol <- which(!(colnames(tmp) %in% negative))\n      \n      data[1, 1] <- sum(tmp[posCol, posCol])\n      data[1, 2] <- sum(tmp[posCol, negCol])\n      data[2, 1] <- sum(tmp[negCol, posCol])      \n      data[2, 2] <- sum(tmp[negCol, negCol])\n      data <- as.table(data)\n      negative <- \"neg\"\n      rm(tmp)\n    }\n  \n  numer <- sum(data[negative, negative])\n  denom <- sum(data[, negative])\n  spec <- ifelse(denom > 0, numer / denom, NA)  \n  spec\n}\n\n\"specificity.matrix\" <- function(data, negative = rownames(data)[-1], ...)\n{\n  data <- as.table(data)\n  specificity.table(data)\n}\n\nconfusionMatrix <- function(data, ...){\n   UseMethod(\"confusionMatrix\")\n  }\nconfusionMatrix.default <- function(data, reference, positive = NULL,\n                                    dnn = c(\"Prediction\", \"Reference\"),\n                                    prevalence = NULL, ...)\n{\n  #library(e1071)\n  if(!is.factor(data)) data <- factor(data)\n  if(!is.factor(reference)) reference <- factor(reference)\n  if(!is.character(positive) & !is.null(positive)) stop(\"positive argument must be character\")\n\n  if(length(levels(data)) != length(levels(reference)))\n    stop(\"the data and reference factors must have the same number of levels\")\n  \n  if(any(levels(data) != levels(reference)))\n    stop(\"the data and reference values must have exactly the same levels\")\n  \n  classLevels <- levels(data)\n  numLevels <- length(classLevels)\n  if(numLevels < 2) \n    stop(\"there must be at least 2 factors levels in the data\")\n  \n  if(numLevels == 2 & is.null(positive))  positive <- levels(reference)[1]\n  \n  classTable <- table(data, reference, dnn = dnn, ...)\n  \n  confusionMatrix(classTable, positive, prevalence = prevalence)\n}\n\nprint.confusionMatrix <- function(x, digits = max(3, getOption(\"digits\") - 3), printStats = TRUE, ...)\n{\n   cat(\"Confusion Matrix and Statistics\\n\\n\") \n   print(x$table, ...)\n   if(printStats)\n   {\n      overall <- signif(x$overall, digits = digits)\n      accCI <- paste(\"(\", paste(overall[ c(\"AccuracyLower\", \"AccuracyUpper\")],\n                     collapse = \", \"), \")\", sep = \"\")      \n      overallText <- c(paste(overall[\"Accuracy\"]), accCI,\n                       paste(overall[c(\"AccuracyNull\", \"AccuracyPValue\")]),\n                       \"\", paste(overall[\"Kappa\"]))\n      overallNames <- c(\"Accuracy\", \"95% CI\",\n                        \"No Information Rate\",\n                        \"P-Value [Acc > NIR]\",\n                        \"\",\n                        \"Kappa\")\n                        \n      if(dim(x$table)[1] > 2)\n      {\n         cat(\"\\nOverall Statistics\\n\")\n         overallNames <- ifelse(overallNames == \"\", \"\", paste(overallNames, \":\"))\n         out <- cbind(format(overallNames, justify = \"right\"), overallText)\n         colnames(out) <- rep(\"\", ncol(out))\n         rownames(out) <- rep(\"\", nrow(out))\n         \n         print(out, quote = FALSE)\n         \n         cat(\"\\nStatistics by Class:\\n\\n\")\n         print(t(x$byClass), digits = digits)\n         \n      } else {\n\n         overallText <- c(overallText, \"\", paste(signif(x$byClass, digits = digits)))\n         overallNames <- c(overallNames, \"\", names(x$byClass))\n         overallNames <- ifelse(overallNames == \"\", \"\", paste(overallNames, \":\"))\n         overallNames <- c(overallNames, \"\", \"'Positive' Class :\")\n         overallText <- c(overallText, \"\", x$positive)\n         out <- cbind(format(overallNames, justify = \"right\"),overallText)\n         colnames(out) <- rep(\"\", ncol(out))\n         rownames(out) <- rep(\"\", nrow(out))\n         out <- rbind(out, rep(\"\", 2))\n         print(out, quote = FALSE)\n      }        \n   }\n   invisible(x)   \n}\n\nclassAgreement <- function (tab, match.names=FALSE) \n{\n    n <- sum(tab)\n    ni <- apply(tab, 1, sum)\n    nj <- apply(tab, 2, sum)\n\n    ## patch for matching factors\n    if (match.names && !is.null(dimnames(tab))) {\n      lev <- intersect (colnames (tab), rownames(tab))\n      p0 <- sum(diag(tab[lev,lev]))/n\n      pc <- sum(ni[lev] * nj[lev])/n^2\n    } else { # cutoff larger dimension\n      m <- min(length(ni), length(nj))\n      p0 <- sum(diag(tab[1:m, 1:m]))/n\n      pc <- sum(ni[1:m] * nj[1:m])/n^2\n    }\n    n2 <- choose(n, 2)\n    rand <- 1 + (sum(tab^2) - (sum(ni^2) + sum(nj^2))/2)/n2\n    nis2 <- sum(choose(ni[ni > 1], 2))\n    njs2 <- sum(choose(nj[nj > 1], 2))\n    crand <- (sum(choose(tab[tab > 1], 2)) - (nis2 * njs2)/n2)/((nis2 + \n        njs2)/2 - (nis2 * njs2)/n2)\n    list(diag = p0, kappa = (p0 - pc)/(1 - pc), rand = rand, \n        crand = crand)\n}\n\nmatchClasses <- function(tab, method = \"rowmax\", iter=1, maxexact=9,\n                         verbose=TRUE){\n\n    methods <- c(\"rowmax\", \"greedy\", \"exact\")\n    method <- pmatch(method, methods)\n    \n    rmax <- apply(tab,1,which.max)\n    myseq <- 1:ncol(tab)\n    cn <- colnames(tab)\n    rn <- rownames(tab)\n    if(is.null(cn)){\n        cn <- myseq\n    }\n    if(is.null(rn)){\n        rn <- myseq\n    }\n    \n    if(method==1){\n        retval <- rmax\n    }\n    if(method==2 | method==3){\n        if(ncol(tab)!=nrow(tab)){\n            stop(\"Unique matching only for square tables.\")\n        }\n        dimnames(tab) <- list(myseq, myseq)\n        cmax <- apply(tab,2,which.max)\n        retval <- rep(NA, ncol(tab))\n        names(retval) <- colnames(tab)\n\n        baseok <- cmax[rmax]==myseq\n        for(k in myseq[baseok]){\n            therow <- (tab[k,])[-rmax[k]]\n            thecol <- (tab[, rmax[k]])[-k]            \n            if(max(outer(therow, thecol, \"+\")) < tab[k, rmax[k]]){\n                retval[k] <- rmax[k]\n            }\n            else{\n                baseok[k] <- FALSE\n            }\n        }\n        \n        if(verbose){\n            cat(\"Direct agreement:\", sum(baseok),\n                \"of\", ncol(tab), \"pairs\\n\")\n        }\n        if(!all(baseok)){\n            if(method==3){\n                if(sum(!baseok)>maxexact){\n                    method <- 2\n                    warning(paste(\"Would need permutation of\", sum(!baseok),\n                                  \"numbers, resetting to greedy search\\n\"))\n                }\n                else{\n                    iter <- gamma(ncol(tab)-sum(baseok)+1)\n                    if(verbose){\n                        cat(\"Iterations for permutation matching:\", iter, \"\\n\")\n                    }\n                    perm <- permutations(ncol(tab)-sum(baseok))\n                }\n            }\n            \n            ## rest for permute matching\n            if(any(baseok)){\n                rest <- myseq[-retval[baseok]]\n            }\n            else{\n                rest <- myseq\n            }\n            \n            for(l in 1:iter){\n                newretval <- retval\n                if(method == 2){\n                    ok <- baseok\n                    while(sum(!ok)>1){\n                        rest <- myseq[!ok]\n                        k <- sample(rest, 1)\n                        if(any(ok)){\n                            rmax <- tab[k, -newretval[ok]]\n                        }\n                        else{\n                            rmax <- tab[k,]\n                        }\n                        newretval[k] <- as.numeric(names(rmax)[which.max(rmax)])\n                        ok[k] <- TRUE\n                    }\n                    newretval[!ok] <- myseq[-newretval[ok]]\n                }\n                else{\n                    newretval[!baseok] <- rest[perm[l,]]\n                }\n                \n                if(l>1){\n                    agree <- sum(diag(tab[,newretval]))/sum(tab)\n                    if(agree>oldagree){\n                        retval <- newretval\n                        oldagree <- agree\n                    }\n                }\n                else{\n                    retval <- newretval\n                    agree <- oldagree <- sum(diag(tab[,newretval]))/sum(tab)\n                }\n            }\n        }\n    }\n\n    if(verbose){\n        cat(\"Cases in matched pairs:\",\n            round(100*sum(diag(tab[,retval]))/sum(tab), 2), \"%\\n\")\n    }\n            \n    if(any(as.character(myseq)!=cn)){\n        retval <- cn[retval]\n    }\n    names(retval) <- rn\n    \n    retval\n}\n\ncompareMatchedClasses <- function(x, y,\n                                  method=\"rowmax\", iter=1, maxexact=9,\n                                  verbose=FALSE)\n{\n    if(missing(y)){\n        retval <- list(diag=matrix(NA, nrow=ncol(x), ncol=ncol(x)),\n                       kappa=matrix(NA, nrow=ncol(x), ncol=ncol(x)),\n                       rand=matrix(NA, nrow=ncol(x), ncol=ncol(x)),\n                       crand=matrix(NA, nrow=ncol(x), ncol=ncol(x)))\n        for(k in 1:(ncol(x)-1)){\n            for(l in (k+1):ncol(x)){\n                tab <- table(x[,k], x[,l])\n                m <- matchClasses(tab, method=method, iter=iter,\n                                  verbose=verbose, maxexact=maxexact)\n                a <- classAgreement(tab[,m])\n                retval$diag[k,l] <- a$diag\n                retval$kappa[k,l] <- a$kappa\n                retval$rand[k,l] <- a$rand\n                retval$crand[k,l] <- a$crand\n            }\n        }\n    }\n    else{\n        x <- as.matrix(x)\n        y <- as.matrix(y)\n        retval <- list(diag=matrix(NA, nrow=ncol(x), ncol=ncol(y)),\n                       kappa=matrix(NA, nrow=ncol(x), ncol=ncol(y)),\n                       rand=matrix(NA, nrow=ncol(x), ncol=ncol(y)),\n                       crand=matrix(NA, nrow=ncol(x), ncol=ncol(y)))\n        for(k in 1:ncol(x)){\n            for(l in 1:ncol(y)){\n                tab <- table(x[,k], y[,l])\n                m <- matchClasses(tab, method=method, iter=iter,\n                                  verbose=verbose, maxexact=maxexact)\n                a <- classAgreement(tab[,m])\n                retval$diag[k,l] <- a$diag\n                retval$kappa[k,l] <- a$kappa\n                retval$rand[k,l] <- a$rand\n                retval$crand[k,l] <- a$crand\n            }\n        }\n    }\n    retval\n}\n\npermutations <- function(n) {\n    if(n ==1)\n        return(matrix(1))\n    else if(n<2)\n        stop(\"n must be a positive integer\")\n    \n    z <- matrix(1)\n    for (i in 2:n) { \n        x <- cbind(z, i)\n        a <- c(1:i, 1:(i - 1))\n        z <- matrix(0, ncol=ncol(x), nrow=i*nrow(x))\n        z[1:nrow(x),] <- x \n        for (j in 2:i-1) { \n            z[j*nrow(x)+1:nrow(x),] <- x[, a[1:i+j]] \n        } \n    } \n    dimnames(z) <- NULL\n    z\n} \n\nconfusionMatrix.table <- function(data, positive = NULL, prevalence = NULL, ...)\n{\n  #library(e1071)\n  if(length(dim(data)) != 2) stop(\"the table must have two dimensions\")\n  if(!all.equal(nrow(data), ncol(data))) stop(\"the table must nrow = ncol\")\n  if(!all.equal(rownames(data), colnames(data))) stop(\"the table must the same classes in the same order\")\n  if(!is.character(positive) & !is.null(positive)) stop(\"positive argument must be character\")\n  \n  classLevels <- rownames(data)\n  numLevels <- length(classLevels)\n  if(numLevels < 2) \n    stop(\"there must be at least 2 factors levels in the data\")\n  \n  if(numLevels == 2 & is.null(positive))  positive <- rownames(data)[1]\n\n  if(numLevels == 2 & !is.null(prevalence) && length(prevalence) != 1)\n    stop(\"with two levels, one prevalence probability must be specified\")\n\n  if(numLevels > 2 & !is.null(prevalence) && length(prevalence) != numLevels)\n    stop(\"the number of prevalence probability must be the same as the number of levels\")\n\n  if(numLevels > 2 & !is.null(prevalence) && is.null(names(prevalence)))\n    stop(\"with >2 classes, the prevalence vector must have names\")\n  \n  propCI <- function(x) { binom.test(sum(diag(x)), sum(x))$conf.int }\n\n  propTest <- function(x) {out <- binom.test(sum(diag(x)), sum(x),\n                           p = max(apply(x, 2, sum)/sum(x)),\n                           alternative = \"greater\")\n      unlist(out[c(\"null.value\", \"p.value\")])\n    }\n  \n  overall <- c(unlist(classAgreement(data))[c(\"diag\", \"kappa\")],\n               propCI(data), propTest(data))\n  \n  names(overall) <- c(\"Accuracy\", \"Kappa\", \"AccuracyLower\", \"AccuracyUpper\", \"AccuracyNull\", \n                      \"AccuracyPValue\")  \n  if(numLevels == 2)\n    {\n      if(is.null(prevalence)) prevalence <- sum(data[, positive])/sum(data)\n      negative <- classLevels[!(classLevels %in% positive)]\n      tableStats <- c(sensitivity.table(data, positive),\n                      specificity.table(data, negative),\n                      posPredValue.table(data, positive, prevalence = prevalence),\n                      negPredValue.table(data, negative, prevalence = prevalence),\n                      prevalence,\n                      sum(data[positive, positive])/sum(data),\n                      sum(data[positive, ])/sum(data))\n      names(tableStats) <- c(\"Sensitivity\", \"Specificity\",\n                             \"Pos Pred Value\", \"Neg Pred Value\",\n                             \"Prevalence\", \"Detection Rate\",\n                                \"Detection Prevalence\")       \n    } else {\n\n      tableStats <- matrix(NA, nrow = length(classLevels), ncol = 7)\n      \n      for(i in seq(along = classLevels))\n        {\n          pos <- classLevels[i]\n          neg <- classLevels[!(classLevels %in% classLevels[i])]\n          prev <- if(is.null(prevalence)) sum(data[, pos])/sum(data) else prevalence[pos]\n          tableStats[i,] <- c(sensitivity.table(data, pos),\n                              specificity.table(data, neg),\n                              posPredValue.table(data, pos, prevalence = prev),\n                              negPredValue.table(data, neg, prevalence = prev),\n                              prev,\n                              sum(data[pos, pos])/sum(data),\n                              sum(data[pos, ])/sum(data))          \n\n        }\n      rownames(tableStats) <- paste(\"Class:\", classLevels)\n      colnames(tableStats) <- c(\"Sensitivity\", \"Specificity\",\n                                \"Pos Pred Value\", \"Neg Pred Value\",\n                                \"Prevalence\", \"Detection Rate\",\n                                \"Detection Prevalence\")  \n    }\n\n  structure(list(positive = positive,\n                 table = data, \n                 overall = overall, \n                 byClass = tableStats,\n                 dots = list(...)), \n            class = \"confusionMatrix\")\n}\n\nas.matrix.confusionMatrix <- function(x, what=\"xtabs\", ...)\n{\n  if(!(what %in% c(\"xtabs\", \"overall\", \"classes\")))\n    stop(\"what must be either xtabs, overall or classes\")\n  out <- switch(what, xtabs = matrix(as.vector(x$table),\n                  nrow = length(colnames(x$table)),\n                  dimnames = list(rownames(x$table), colnames(x$table))),\n                overall = as.matrix(x$overall),\n                classes = as.matrix(x$byClass))\n  if(what == \"classes\")\n    {\n      if(length(colnames(x$table)) > 2)\n        {\n          out <- t(out)\n          colnames(out) <- gsub(\"Class: \", \"\", colnames(out), fixed = TRUE)\n        }\n    }\n  out\n}\n\nas.table.confusionMatrix <- function(x, ...)  x$table\n\n",
    "created" : 1375713824870.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2753938087",
    "id" : "CA300905",
    "lastKnownWriteTime" : 1375713944,
    "path" : "C:/Share/tcormier/scripts/R/Evans_Functions.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}